{"cells":[{"cell_type":"markdown","metadata":{},"source":["It is important to say that this notebook was taken from lux code for \"stable baselines 3\":\n","https://github.com/Lux-AI-Challenge/Lux-Design-S2/blob/main/examples/sb3.py\n","I made only several changes.\n","I hope it will be useful for those who don't know where to find RL model examples."]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: stable-baselines3 in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (1.8.0)\n","Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from stable-baselines3) (1.24.2)\n","Requirement already satisfied: torch>=1.11 in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from stable-baselines3) (2.0.0)\n","Requirement already satisfied: gym==0.21 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from stable-baselines3) (0.21.0)\n","Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from stable-baselines3) (3.7.1)\n","Requirement already satisfied: pandas in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from stable-baselines3) (2.0.0)\n","Requirement already satisfied: importlib-metadata~=4.13 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from stable-baselines3) (4.13.0)\n","Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from stable-baselines3) (2.2.1)\n","Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from importlib-metadata~=4.13->stable-baselines3) (3.15.0)\n","Requirement already satisfied: filelock in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.11->stable-baselines3) (3.12.0)\n","Requirement already satisfied: networkx in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.11->stable-baselines3) (3.1)\n","Requirement already satisfied: sympy in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.11->stable-baselines3) (1.11.1)\n","Requirement already satisfied: jinja2 in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from torch>=1.11->stable-baselines3) (3.1.2)\n","Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from torch>=1.11->stable-baselines3) (4.5.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (5.12.0)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (1.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (2.8.2)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (9.5.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (3.0.9)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (4.39.3)\n","Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (23.1)\n","Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->stable-baselines3) (0.11.0)\n","Requirement already satisfied: tzdata>=2022.1 in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from pandas->stable-baselines3) (2023.3)\n","Requirement already satisfied: pytz>=2020.1 in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from pandas->stable-baselines3) (2023.3)\n","Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from jinja2->torch>=1.11->stable-baselines3) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in c:\\users\\olcao\\appdata\\roaming\\python\\python38\\site-packages (from sympy->torch>=1.11->stable-baselines3) (1.3.0)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: luxai_s2 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (2.1.9)\n","Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (1.24.2)\n","Requirement already satisfied: termcolor in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (2.2.0)\n","Requirement already satisfied: gym==0.21.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (0.21.0)\n","Requirement already satisfied: pygame in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (2.3.0)\n","Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (1.10.1)\n","Requirement already satisfied: importlib-metadata<5.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (4.13.0)\n","Requirement already satisfied: vec-noise in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (1.1.4)\n","Requirement already satisfied: pettingzoo in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (1.22.3)\n","Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from luxai_s2) (3.7.1)\n","Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from gym==0.21.0->luxai_s2) (2.2.1)\n","Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from importlib-metadata<5.0->luxai_s2) (3.15.0)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (2.8.2)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (4.39.3)\n","Requirement already satisfied: importlib-resources>=3.2.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (5.12.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (9.5.0)\n","Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (0.11.0)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (1.0.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from matplotlib->luxai_s2) (1.4.4)\n","Requirement already satisfied: gymnasium>=0.26.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from pettingzoo->luxai_s2) (0.28.1)\n","Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from gymnasium>=0.26.0->pettingzoo->luxai_s2) (1.0.0)\n","Requirement already satisfied: typing-extensions>=4.3.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from gymnasium>=0.26.0->pettingzoo->luxai_s2) (4.5.0)\n","Requirement already satisfied: farama-notifications>=0.0.1 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from gymnasium>=0.26.0->pettingzoo->luxai_s2) (0.0.4)\n","Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->luxai_s2) (1.16.0)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: gym==0.21.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (0.21.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from gym==0.21.0) (2.2.1)\n","Requirement already satisfied: numpy>=1.18.0 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from gym==0.21.0) (1.24.2)\n","Defaulting to user installation because normal site-packages is not writeable\n","Collecting importlib-metadata==4.12.0\n","  Downloading importlib_metadata-4.12.0-py3-none-any.whl (21 kB)\n","Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\envs\\luxai\\lib\\site-packages (from importlib-metadata==4.12.0) (3.15.0)\n","Installing collected packages: importlib-metadata\n","Successfully installed importlib-metadata-4.12.0\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","stable-baselines3 1.8.0 requires importlib-metadata~=4.13, but you have importlib-metadata 4.12.0 which is incompatible.\n"]}],"source":["!pip install stable-baselines3\n","!pip install --upgrade luxai_s2\n","!pip install gym==0.21.0\n","!pip install importlib-metadata==4.12.0"]},{"cell_type":"markdown","metadata":{},"source":["Please, restart your kernel after loading libraries"]},{"cell_type":"markdown","metadata":{},"source":["Here is the main part of the code for PPO model of stable baselines 3:"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-31T18:27:03.675808Z","iopub.status.busy":"2023-01-31T18:27:03.675333Z","iopub.status.idle":"2023-01-31T18:27:05.335711Z","shell.execute_reply":"2023-01-31T18:27:05.334710Z","shell.execute_reply.started":"2023-01-31T18:27:03.675722Z"},"trusted":true},"outputs":[],"source":["import copy\n","import os\n","import os.path as osp\n","import gym\n","import numpy as np\n","import torch as th\n","import torch.nn as nn\n","from gym import spaces\n","from gym.wrappers import TimeLimit\n","from stable_baselines3.common.callbacks import BaseCallback, EvalCallback\n","from stable_baselines3.common.evaluation import evaluate_policy\n","from stable_baselines3.common.monitor import Monitor\n","from stable_baselines3.common.utils import set_random_seed\n","from stable_baselines3.common.vec_env import (\n","    DummyVecEnv,\n","    SubprocVecEnv,\n","    VecCheckNan,\n","    VecVideoRecorder,\n",")\n","from stable_baselines3.ppo import PPO\n","\n","from luxai_s2.state import ObservationStateDict, StatsStateDict, create_empty_stats\n","from luxai_s2.utils.heuristics.factory import build_single_heavy\n","from luxai_s2.utils.heuristics.factory_placement import place_near_random_ice\n","from luxai_s2.wrappers import SB3Wrapper\n","from wrappers import SimpleUnitDiscreteController, SimpleUnitObservationWrapper\n","\n","\n","class CustomEnvWrapper(gym.Wrapper):\n","    def __init__(self, env: gym.Env) -> None:\n","        \"\"\"\n","        Adds a custom reward and turns the LuxAI_S2 environment into a single-agent environment for easy training\n","        \"\"\"\n","        super().__init__(env)\n","        self.prev_step_metrics = None\n","\n","    def step(self, action):\n","        agent = \"player_0\"\n","        opp_agent = \"player_1\"\n","\n","        opp_factories = self.env.state.factories[opp_agent]\n","        for k in opp_factories:\n","            factory = opp_factories[k]\n","            factory.cargo.water = 1000 # set enemy factories to have 1000 water to keep them alive the whole around and treat the game as single-agent\n","\n","        action = {agent: action}\n","        obs, reward, done, info = super().step(action)\n","\n","        # this is the observation seen by both agents\n","        shared_obs: ObservationStateDict = self.env.prev_obs[agent]\n","        done = done[agent]\n","\n","        # we collect stats on teams here:\n","        stats: StatsStateDict = self.env.state.stats[agent]\n","        \n","        # compute reward\n","        # we simply want to encourage the heavy units to move to ice tiles\n","        # and mine them and then bring them back to the factory and dump it\n","        # as well as survive as long as possible\n","\n","        factories = shared_obs[\"factories\"][agent]\n","        factory_pos = None\n","        for unit_id in factories:\n","            factory = factories[unit_id]\n","            # note that ice converts to water at a 4:1 ratio\n","            factory_pos = np.array(factory[\"pos\"])\n","            break\n","        units = shared_obs[\"units\"][agent]\n","        unit_deliver_ice_reward = 0\n","        unit_move_to_ice_reward = 0\n","        unit_overmining_penalty = 0\n","        penalize_power_waste = 0\n","\n","        ice_map = shared_obs[\"board\"][\"ice\"]\n","        ice_tile_locations = np.argwhere(ice_map == 1)\n","\n","        def manhattan_dist(p1, p2):\n","            return abs(p1[0] - p2[0]) + abs(p1[1] - p2[1])\n","\n","        unit_power = 0\n","        for unit_id in units:\n","            unit = units[unit_id]\n","            if unit[\"unit_type\"] == \"HEAVY\":\n","                pos = np.array(unit[\"pos\"])\n","                ice_tile_distances = np.mean((ice_tile_locations - pos) ** 2, 1)\n","                closest_ice_tile = ice_tile_locations[np.argmin(ice_tile_distances)]\n","                dist_to_ice = manhattan_dist(closest_ice_tile, pos)\n","                unit_power = unit[\"power\"]\n","                if unit[\"cargo\"][\"ice\"] < 20:\n","\n","                    dist_penalty = min(\n","                        1.0, dist_to_ice / (10)\n","                    )  # go beyond 12 squares manhattan dist and no reward\n","                    unit_move_to_ice_reward += (\n","                        1 - dist_penalty\n","                    ) * 0.1  # encourage unit to move to ice\n","                else:\n","                    if factory_pos is not None:\n","                        dist_to_factory = manhattan_dist(pos, factory_pos)\n","                        dist_penalty = min(1.0, dist_to_factory / 10)\n","                        unit_deliver_ice_reward = (\n","                            0.2 + (1 - dist_penalty) * 0.1\n","                        )  # encourage unit to move back to factory\n","                if action[agent] == 15 and unit[\"power\"] < 70:\n","                    # penalize the agent for trying to dig with insufficient power, which wastes 10 power for trying to update the action queue\n","                    penalize_power_waste -= 0.005\n","\n","        # save some stats to the info object so we can record it with our SB3 logger\n","        info = dict()\n","        metrics = dict()\n","        metrics[\"ice_dug\"] = (\n","            stats[\"generation\"][\"ice\"][\"HEAVY\"] + stats[\"generation\"][\"ice\"][\"LIGHT\"]\n","        )\n","        metrics[\"water_produced\"] = stats[\"generation\"][\"water\"]\n","        metrics[\"action_queue_updates_success\"] = stats[\"action_queue_updates_success\"]\n","        metrics[\"action_queue_updates_total\"] = stats[\"action_queue_updates_total\"]\n","\n","        metrics[\"unit_deliver_ice_reward\"] = unit_deliver_ice_reward\n","        metrics[\"unit_move_to_ice_reward\"] = unit_move_to_ice_reward\n","\n","        info[\"metrics\"] = metrics\n","\n","        reward = (\n","            0\n","            + unit_move_to_ice_reward\n","            + unit_deliver_ice_reward\n","            + unit_overmining_penalty\n","            + metrics[\"water_produced\"] / 10 + penalize_power_waste\n","        )\n","        reward = reward\n","        if self.prev_step_metrics is not None:\n","            ice_dug_this_step = metrics[\"ice_dug\"] - self.prev_step_metrics[\"ice_dug\"]\n","            water_produced_this_step = (\n","                metrics[\"water_produced\"] - self.prev_step_metrics[\"water_produced\"]\n","            )\n","            # reward += ice_dug_this_step # reward agent for digging ice\n","            # reward += water_produced_this_step * 100 # reward agent even more producing water by delivering ice back to base\n","        self.prev_step_metrics = copy.deepcopy(metrics)\n","        return obs[\"player_0\"], reward, done, info\n","\n","    def reset(self, **kwargs):\n","        obs = self.env.reset(**kwargs)[\"player_0\"]\n","        self.prev_step_metrics = None\n","        return obs\n","\n","\n","class Parse_args:\n","    def __init__(self):\n","        self.max_episode_steps = 100\n","        self.seed = 13\n","        self.n_envs = 8\n","        self.total_timesteps = 2000000\n","        self.log_path = \"logs\"\n","        self.model_path = '/kaggle/working/latest_model'\n","        self.eval = False\n","    \n","    \n","def make_env(env_id: str, rank: int, seed: int = 0, max_episode_steps=100):\n","    def _init() -> gym.Env:\n","        # verbose = 0\n","        # collect stats so we can create reward functions\n","        # max factories set to 2 for simplification and keeping returns consistent as we survive longer if there are more initial resources\n","        env = gym.make(env_id, verbose=0, collect_stats=True, MAX_FACTORIES=2)\n","\n","        # Add a SB3 wrapper to make it work with SB3 and simplify the action space with the controller\n","        # this will remove the bidding phase and factory placement phase. For factory placement we use\n","        # the provided place_near_random_ice function which will randomly select an ice tile and place a factory near it.\n","        env = SB3Wrapper(\n","            env,\n","            controller=SimpleUnitDiscreteController(env.state.env_cfg),\n","            factory_placement_policy=place_near_random_ice,\n","            heuristic_policy=build_single_heavy,\n","        )\n","        env = SimpleUnitObservationWrapper(\n","            env\n","        )  # changes observation to include a few simple features\n","        env = CustomEnvWrapper(env)  # convert to single agent and add our reward\n","        env = TimeLimit(\n","            env, max_episode_steps=max_episode_steps\n","        )  # set horizon to 100 to make training faster. Default is 1000\n","        env = Monitor(env)  # for SB3 to allow it to record metrics\n","        env.reset(seed=seed + rank)\n","        set_random_seed(seed)\n","        return env\n","\n","    return _init\n","\n","\n","env_id = \"LuxAI_S2-v0\"\n","\n","from collections import defaultdict\n","\n","\n","class TensorboardCallback(BaseCallback):\n","    def __init__(self, tag: str, verbose=0):\n","        super().__init__(verbose)\n","        self.tag = tag\n","\n","    def _on_step(self) -> bool:\n","        c = 0\n","        \n","        for i, done in enumerate(self.locals[\"dones\"]):\n","            if done:\n","                info = self.locals[\"infos\"][i]\n","                c += 1\n","                for k in info[\"metrics\"]:\n","                    stat = info[\"metrics\"][k]\n","                    self.logger.record_mean(f\"{self.tag}/{k}\", stat)\n","        return True\n","\n","\n","def evaluate(args, model,):\n","    model = model.load(args.model_path)\n","    video_length = 1000  # default horizon\n","    eval_env = SubprocVecEnv([make_env(env_id, i, max_episode_steps=1000) for i in range(args.n_envs)])\n","    eval_env = VecVideoRecorder(\n","        eval_env,\n","        osp.join(args.log_path, \"eval_videos\"),\n","        record_video_trigger=lambda x: x == 0,\n","        video_length=video_length,\n","        name_prefix=f\"evaluation_video\",\n","    )\n","    eval_env.reset()\n","    out =evaluate_policy(model, eval_env, render=False, deterministic=False)\n","    print(out)\n","\n","def train(args, model: PPO,):\n","    eval_env = SubprocVecEnv([make_env(env_id, i, max_episode_steps=1000) for i in range(4)])\n","    video_length = 1000\n","    eval_env = VecVideoRecorder(\n","        eval_env,\n","        osp.join(args.log_path, \"eval_videos\"),\n","        record_video_trigger=lambda x: x == 0,\n","        video_length=video_length,\n","        name_prefix=f\"evaluation-{env_id}\",\n","    )\n","    eval_callback = EvalCallback(\n","        eval_env,\n","        best_model_save_path=osp.join(args.log_path, \"models\"),\n","        log_path=osp.join(args.log_path, \"eval_logs\"),\n","        eval_freq=24_000,\n","        deterministic=False,\n","        render=False,\n","    )\n","    model.learn(\n","        args.total_timesteps,\n","        callback=[TensorboardCallback(tag=\"train_metrics\"), eval_callback],\n","    )\n","    \n","    model.save(args.log_path, \"latest_model\")"]},{"cell_type":"markdown","metadata":{},"source":["Here is the main function which creates your PPO model:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-01-31T18:27:06.158389Z","iopub.status.busy":"2023-01-31T18:27:06.157707Z","iopub.status.idle":"2023-01-31T18:46:02.722277Z","shell.execute_reply":"2023-01-31T18:46:02.720648Z","shell.execute_reply.started":"2023-01-31T18:27:06.158348Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training with args <__main__.Parse_args object at 0x00000214EF330940>\n"]},{"ename":"EOFError","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)","File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\luxai\\lib\\multiprocessing\\connection.py:312\u001b[0m, in \u001b[0;36mPipeConnection._recv_bytes\u001b[1;34m(self, maxsize)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m     nread, err \u001b[39m=\u001b[39m ov\u001b[39m.\u001b[39;49mGetOverlappedResult(\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    313\u001b[0m     \u001b[39mif\u001b[39;00m err \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n","\u001b[1;31mBrokenPipeError\u001b[0m: [WinError 109] The pipe has been ended","\nDuring handling of the above exception, another exception occurred:\n","\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[1;32mIn[13], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     28\u001b[0m     parse_args \u001b[39m=\u001b[39m Parse_args()\n\u001b[1;32m---> 29\u001b[0m     main(parse_args)\n","Cell \u001b[1;32mIn[13], line 4\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining with args\u001b[39m\u001b[39m\"\u001b[39m, args)\n\u001b[0;32m      3\u001b[0m set_random_seed(args\u001b[39m.\u001b[39mseed)\n\u001b[1;32m----> 4\u001b[0m env \u001b[39m=\u001b[39m SubprocVecEnv([make_env(env_id, i, max_episode_steps\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mmax_episode_steps) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(args\u001b[39m.\u001b[39;49mn_envs)])\n\u001b[0;32m      5\u001b[0m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m      6\u001b[0m rollout_steps \u001b[39m=\u001b[39m \u001b[39m4_000\u001b[39m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\stable_baselines3\\common\\vec_env\\subproc_vec_env.py:112\u001b[0m, in \u001b[0;36mSubprocVecEnv.__init__\u001b[1;34m(self, env_fns, start_method)\u001b[0m\n\u001b[0;32m    109\u001b[0m     work_remote\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mremotes[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msend((\u001b[39m\"\u001b[39m\u001b[39mget_spaces\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m--> 112\u001b[0m observation_space, action_space \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mremotes[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mrecv()\n\u001b[0;32m    113\u001b[0m VecEnv\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mlen\u001b[39m(env_fns), observation_space, action_space)\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\luxai\\lib\\multiprocessing\\connection.py:250\u001b[0m, in \u001b[0;36m_ConnectionBase.recv\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m    249\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[1;32m--> 250\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_recv_bytes()\n\u001b[0;32m    251\u001b[0m \u001b[39mreturn\u001b[39;00m _ForkingPickler\u001b[39m.\u001b[39mloads(buf\u001b[39m.\u001b[39mgetbuffer())\n","File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\luxai\\lib\\multiprocessing\\connection.py:321\u001b[0m, in \u001b[0;36mPipeConnection._recv_bytes\u001b[1;34m(self, maxsize)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m e\u001b[39m.\u001b[39mwinerror \u001b[39m==\u001b[39m _winapi\u001b[39m.\u001b[39mERROR_BROKEN_PIPE:\n\u001b[1;32m--> 321\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m         \u001b[39mraise\u001b[39;00m\n","\u001b[1;31mEOFError\u001b[0m: "]}],"source":["def main(args):\n","    print(\"Training with args\", args)\n","    set_random_seed(args.seed)\n","    env = SubprocVecEnv([make_env(env_id, i, max_episode_steps=args.max_episode_steps) for i in range(args.n_envs)])\n","    env.reset()\n","    rollout_steps = 4_000\n","    policy_kwargs = dict(net_arch=(128, 128))\n","    model = PPO(\n","        \"MlpPolicy\",\n","        env,\n","        n_steps=rollout_steps // args.n_envs,\n","        batch_size=800,\n","        learning_rate=1e-3,\n","        policy_kwargs=policy_kwargs,\n","        verbose=1,\n","        n_epochs=3,\n","        target_kl=0.07,\n","        gamma=0.97,\n","        device='auto',\n","        tensorboard_log=osp.join(args.log_path),\n","    )\n","    if args.eval:\n","        evaluate(args, model)\n","    else:\n","        train(args, model)\n","\n","if __name__ == \"__main__\":\n","    parse_args = Parse_args()\n","    main(parse_args)"]},{"cell_type":"markdown","metadata":{},"source":["My code is still raw but I'm ready to hear your advice for improving it or you can improve it on your own."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.16"}},"nbformat":4,"nbformat_minor":4}
